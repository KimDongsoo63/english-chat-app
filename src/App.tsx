import React, { useState, useEffect, useRef } from 'react';
import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';
import OpenAI from 'openai';
import './App.css';

interface Message {
  text: string;
  sender: 'user' | 'assistant' | 'system';
}

interface UserContext {
  proficiencyLevel: 'beginner' | 'intermediate' | 'advanced';
  recentTopics: string[];
  practicedGrammar: string[];
  introducedVocab: string[];
  commonMistakes: string[];
  interests: string[];
  learningGoals: string[];
  preferredTopics: string[];
}

// ë²„ì „ ì •ë³´ í…ìŠ¤íŠ¸ (ì±„íŒ…ì•± ìƒë‹¨ì— í‘œì‹œ)
const VERSION_DISPLAY = "Ver 1.0.20";

// ì›°ì»´ ë©”ì‹œì§€
const WELCOME_MESSAGE: Message = {
  text: "Hey! How's your day going so far? Found any new books or hobbies lately?",
  sender: 'assistant'
};

// OpenAI client configuration
const openai = new OpenAI({
  apiKey: process.env.REACT_APP_OPENAI_API_KEY,
  dangerouslyAllowBrowser: true
});

// ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°œì„ 
const SYSTEM_PROMPT = `You are a friendly English conversation partner helping users improve their English speaking skills.

Key Points:
1. Maintain natural conversation flow
2. Adjust your language level to match the user
3. Provide gentle corrections when needed
4. Keep the conversation engaging and encouraging
5. Focus on practical, daily conversation topics

Response Format:
1. First, respond naturally to continue the conversation
2. Then, if needed, add a brief correction (marked with ğŸ’¡)
3. Keep responses concise but natural

Example:
User: "I go to store yesterday"
Assistant: "Oh, you went shopping yesterday! What did you buy? 
ğŸ’¡ Quick tip: Use 'went' for past actions."

Remember:
- Be encouraging and friendly
- Focus on communication over perfect grammar
- Keep the conversation flowing naturally
- Help build confidence`;

function App() {
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputText, setInputText] = useState('');
  const [loading, setLoading] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [silenceTimer, setSilenceTimer] = useState<NodeJS.Timeout | null>(null);
  const [inactivityTimer, setInactivityTimer] = useState<NodeJS.Timeout | null>(null);
  const [countdown, setCountdown] = useState<number>(0);
  const [lastUserInteraction, setLastUserInteraction] = useState(Date.now());
  const [deferredPrompt, setDeferredPrompt] = useState<any>(null);
  const [showInstallPrompt, setShowInstallPrompt] = useState(false);
  const currentUtterance = useRef<SpeechSynthesisUtterance | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const [userContext, setUserContext] = useState<UserContext>({
    proficiencyLevel: 'beginner',
    recentTopics: [],
    practicedGrammar: [],
    introducedVocab: [],
    commonMistakes: [],
    interests: [],
    learningGoals: [],
    preferredTopics: []
  });
  const [isUpdateAvailable, setIsUpdateAvailable] = useState(false);
  const [voicesLoaded, setVoicesLoaded] = useState(false);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const {
    transcript,
    resetTranscript,
    browserSupportsSpeechRecognition,
    isMicrophoneAvailable,
    listening
  } = useSpeechRecognition({
    commands: [
      {
        command: '*',
        callback: () => {
          // ìŒì„± ì¸ì‹ ì¤‘ì—ëŠ” ì…ë ¥ í…ìŠ¤íŠ¸ë§Œ ì—…ë°ì´íŠ¸
          if (!isListening) return;
          setInputText(transcript.trim());
        }
      }
    ]
  });

  // ìŒì„± ì¸ì‹ ì„¤ì • ìµœì í™”
  useEffect(() => {
    if (browserSupportsSpeechRecognition) {
      // @ts-ignore (SpeechRecognition ì„¤ì •ì„ ìœ„í•´ ë¬´ì‹œ)
      const recognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognitionInstance = new recognition();
      
      // ì¸ì‹ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ì„¤ì •
      recognitionInstance.continuous = true; // ì—°ì† ì¸ì‹ ëª¨ë“œ
      recognitionInstance.interimResults = true; // ì¤‘ê°„ ê²°ê³¼ í™œì„±í™”
      recognitionInstance.maxAlternatives = 3; // ëŒ€ì²´ ì¸ì‹ ê²°ê³¼ ìˆ˜ ì¦ê°€
      
      // ìŒì„± ì¸ì‹ í’ˆì§ˆ ì„¤ì •
      recognitionInstance.lang = 'en-US'; // ë¯¸êµ­ ì˜ì–´ë¡œ ì„¤ì •
      
      // MediaTrackConstraints ì„¤ì •
      // @ts-ignore
      if (recognitionInstance.mediaDevices && recognitionInstance.mediaDevices.getUserMedia) {
        // @ts-ignore
        recognitionInstance.mediaDevices.getUserMedia({
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            channelCount: 1,
            sampleRate: 48000
          }
        });
      }
    }
  }, [browserSupportsSpeechRecognition]);

  // ìŒì„± ì…ë ¥ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³„ë„ì˜ í•¨ìˆ˜
  const handleVoiceInput = React.useCallback((text: string) => {
    if (!text || loading) return;

    // ìŒì„± ì¸ì‹ ê²°ê³¼ ì „ì²˜ë¦¬
    let processedText = text
      .trim()
      .replace(/\s+/g, ' ') // ì¤‘ë³µ ê³µë°± ì œê±°
      .replace(/[.,!?;:]$/, ''); // ë¬¸ì¥ ë êµ¬ë‘ì  ì œê±°

    // ìµœì†Œ ë‹¨ì–´ ìˆ˜ í™•ì¸ (ë„ˆë¬´ ì§§ì€ ì¸ì‹ ê²°ê³¼ ë¬´ì‹œ)
    if (processedText.split(' ').length < 2) {
      console.log('Recognition result too short, ignoring:', processedText);
      return;
    }

    // ë©”ì‹œì§€ ì¶”ê°€
    const userMessage: Message = {
      text: processedText,
      sender: 'user'
    };

    setMessages(prev => [...prev, userMessage]);
    handleSendMessage(processedText, [...messages, userMessage]);
  }, [loading, messages]);

  // ìŒì„± ì¸ì‹ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
  useEffect(() => {
    const handleSpeechStart = () => {
      setIsListening(true);
    };

    const handleSpeechEnd = () => {
      if (isListening && transcript.trim()) {
        handleVoiceInput(transcript.trim());
      } else if (isListening) {
        // ìŒì„±ì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì¢…ë£Œ
        SpeechRecognition.stopListening();
        setIsListening(false);
        resetTranscript();
      }
    };

    if (browserSupportsSpeechRecognition) {
      window.addEventListener('speechend', handleSpeechEnd);
      window.addEventListener('speechstart', handleSpeechStart);
    }

    return () => {
      if (browserSupportsSpeechRecognition) {
        window.removeEventListener('speechend', handleSpeechEnd);
        window.removeEventListener('speechstart', handleSpeechStart);
      }
    };
  }, [browserSupportsSpeechRecognition, isListening, transcript, handleVoiceInput]);

  // Function to handle user inactivity
  const handleInactivity = async () => {
    // ì´ë¯¸ ë¡œë”© ì¤‘ì´ê±°ë‚˜ ìŒì„± ì¸ì‹ ì¤‘ì´ë©´ ë¬´ì‹œ
    if (loading || isListening) return;

    try {
      setLoading(true);
      const response = await openai.chat.completions.create({
        model: "gpt-4-turbo-preview",
        messages: [
          { 
            role: "system", 
            content: `You are helping a complete beginner learn English. 
- Always choose a new, non-repetitive topic from: daily routine, hobbies, food, weather, family, travel, movies, music, sports, pets, school, shopping, feelings, weekend, friends, places, colors, clothes, seasons, holidays, transportation, technology, dreams, plans, chores, or any other simple daily topic.
- Never repeat the same topic twice in a row.
- Ask a very simple, friendly question about that topic.
- Give one short, clear example answer.
- Use only basic vocabulary and grammar.
- Keep the total response under 30 words.
- Format: "Let's talk about [topic]! [question] For example: [simple example]"
- Make it fun and encouraging.`
          }
        ],
        temperature: 1.0,
        max_tokens: 50
      });

      const promptText = response.choices[0].message.content || "Let's talk about your day! What did you do today? For example: I went to the park.";
      
      const promptMessage: Message = {
        text: promptText,
        sender: 'assistant'
      };
      
      setMessages(prev => [...prev, promptMessage]);
      
      // ìŒì„± ì¶œë ¥ ë° íƒ€ì´ë¨¸ ì‹œì‘
      setTimeout(() => {
        speakResponse(promptMessage.text);
        // ìƒˆë¡œìš´ ì£¼ì œ ì œì‹œ í›„ íƒ€ì´ë¨¸ ì‹œì‘
        startInactivityTimer();
      }, 500);
    } catch (error) {
      console.error('Error generating prompt:', error);
    } finally {
      setLoading(false);
    }
  };

  // ìŒì„± ì¶œë ¥ í•¨ìˆ˜
  const speakResponse = (text: string) => {
    if (!window.speechSynthesis) {
      console.error('Speech synthesis not available');
      return;
    }

    // ì´ì „ ìŒì„± ì¶œë ¥ ì¤‘ì§€
    window.speechSynthesis.cancel();
    if (currentUtterance.current) {
      currentUtterance.current = null;
    }

    const utterance = new SpeechSynthesisUtterance(text);
    
    // ì˜ì–´ ìŒì„± ì„ íƒ
    const voices = window.speechSynthesis.getVoices();
    const englishVoice = voices.find(voice => 
      voice.lang.startsWith('en') && voice.name.includes('Female')
    ) || voices.find(voice => voice.lang.startsWith('en'));
    
    if (englishVoice) {
      utterance.voice = englishVoice;
    }

    // ìŒì„± ì„¤ì •
    utterance.rate = 0.9;  // ìì—°ìŠ¤ëŸ¬ìš´ ì†ë„
    utterance.pitch = 1.0;
    utterance.volume = 1.0;
    utterance.lang = 'en-US';

    // ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
    utterance.onstart = () => {
      currentUtterance.current = utterance;
      console.log('Speech started');
    };

    utterance.onend = () => {
      currentUtterance.current = null;
      console.log('Speech ended');
    };

    utterance.onerror = (event) => {
      console.error('Speech error:', event);
      currentUtterance.current = null;
    };

    // ìŒì„± ì¶œë ¥ ì‹œì‘
    window.speechSynthesis.speak(utterance);
  };

  // íƒ€ì´ë¨¸ ì´ˆê¸°í™” í•¨ìˆ˜
  const clearInactivityTimer = () => {
    if (inactivityTimer) {
      clearTimeout(inactivityTimer);
      setInactivityTimer(null);
    }
    setCountdown(0);
  };

  // AI ì‘ë‹µ í›„ íƒ€ì´ë¨¸ ì‹œì‘ í•¨ìˆ˜
  const startInactivityTimer = () => {
    // ê¸°ì¡´ íƒ€ì´ë¨¸ ì´ˆê¸°í™”
    clearInactivityTimer();
    
    // ìŒì„± ì¶œë ¥ì´ ëë‚˜ë©´ íƒ€ì´ë¨¸ ì‹œì‘
    const startTimer = () => {
      setCountdown(20);
      const countdownInterval = setInterval(() => {
        setCountdown(prev => {
          if (prev <= 1) {
            clearInterval(countdownInterval);
            return 0;
          }
          return prev - 1;
        });
      }, 1000);

      const timer = setTimeout(() => {
        setInactivityTimer(null);
        clearInterval(countdownInterval);
        setCountdown(0);
        handleInactivity();
      }, 20000);

      setInactivityTimer(timer);
    };

    // í˜„ì¬ ìŒì„±ì´ ëë‚˜ë©´ íƒ€ì´ë¨¸ ì‹œì‘
    if (currentUtterance.current) {
      currentUtterance.current.onend = () => {
        startTimer();
      };
    } else {
      startTimer();
    }
  };

  // ë©”ì‹œì§€ ì „ì†¡ í•¸ë“¤ëŸ¬
  const handleSend = async () => {
    if (!inputText.trim()) return;
    
    const messageText = inputText.trim();
    
    // ì‚¬ìš©ì ë©”ì‹œì§€ ìƒì„± ë° í‘œì‹œ
    const userMessage: Message = {
      text: messageText,
      sender: 'user'
    };
    
    // ë©”ì‹œì§€ ì¶”ê°€ ë° AI ì‘ë‹µ ìš”ì²­
    setMessages(prev => {
      const newMessages = [...prev, userMessage];
      handleSendMessage(messageText, newMessages);
      return newMessages;
    });
    
    setInputText('');
    resetTranscript();
  };

  // ë§ˆì´í¬ ë²„íŠ¼ í´ë¦­ í•¸ë“¤ëŸ¬ ìˆ˜ì •
  const handleMicClick = async () => {
    // í˜„ì¬ ìŒì„± ì¶œë ¥ ì¤‘ì§€
    if (currentUtterance.current) {
      stopAIVoice();
    }

    // íƒ€ì´ë¨¸ ì´ˆê¸°í™”
    clearInactivityTimer();

    // ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì´ë©´ ë¬´ì‹œ
    if (loading) {
      console.log('Loading in progress, ignoring mic click');
      return;
    }

    if (isListening) {
      // STOP ë²„íŠ¼ì„ í´ë¦­í–ˆì„ ë•Œ
      if (transcript.trim()) {
        handleVoiceInput(transcript.trim());
      }
      // ìŒì„± ì¸ì‹ ì¢…ë£Œ
      SpeechRecognition.stopListening();
      setIsListening(false);
      resetTranscript();
    } else {
      try {
        resetTranscript();
        setInputText('');
        
        // ìŒì„± ì¸ì‹ ì‹œì‘ ì‹œ ê³ í’ˆì§ˆ ì„¤ì • ì ìš©
        await SpeechRecognition.startListening({
          continuous: true,
          language: 'en-US'
        });
        setIsListening(true);
      } catch (error) {
        console.error('Speech recognition error:', error);
        setIsListening(false);
        setMessages(prev => [...prev, {
          text: "Sorry, there was a problem with the microphone. Please try again.",
          sender: 'system'
        }]);
      }
    }
  };

  // ìŒì„± ì¸ì‹ ìƒíƒœ ë™ê¸°í™”
  useEffect(() => {
    if (!listening && isListening) {
      console.log('Speech recognition stopped unexpectedly');
      if (transcript.trim()) {
        handleVoiceInput(transcript.trim());
      } else {
        setIsListening(false);
        resetTranscript();
      }
    }
  }, [listening]);

  // transcript ë³€ê²½ ê°ì§€
  useEffect(() => {
    if (!isListening) return;
    setInputText(transcript.trim());
  }, [transcript, isListening]);

  // ìŒì„± ì¸ì‹ ì—ëŸ¬ ì²˜ë¦¬
  useEffect(() => {
    const handleError = (event: any) => {
      console.error('Speech recognition error:', event);
      setIsListening(false);
      
      // ì‚¬ìš©ìì—ê²Œ ë” ìì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
      let errorMessage = "Sorry, there was a problem with the speech recognition. ";
      if (event.error === 'no-speech') {
        errorMessage += "No speech was detected. Please try again.";
      } else if (event.error === 'audio-capture') {
        errorMessage += "Please check your microphone.";
      } else if (event.error === 'not-allowed') {
        errorMessage += "Please allow microphone access.";
      } else {
        errorMessage += "Please try again.";
      }
      
      setMessages(prev => [...prev, {
        text: errorMessage,
        sender: 'system'
      }]);
    };

    if (browserSupportsSpeechRecognition) {
      window.addEventListener('error', handleError);
    }

    return () => {
      if (browserSupportsSpeechRecognition) {
        window.removeEventListener('error', handleError);
      }
    };
  }, [browserSupportsSpeechRecognition]);

  const stopAIVoice = () => {
    if (currentUtterance.current) {
      window.speechSynthesis.cancel();
      currentUtterance.current = null;
    }
  };

  // PWA ì—…ë°ì´íŠ¸ í•¸ë“¤ëŸ¬
  const handleUpdate = () => {
    if ('serviceWorker' in navigator) {
      navigator.serviceWorker.ready.then(registration => {
        if (registration.waiting) {
          registration.waiting.postMessage({ type: 'SKIP_WAITING' });
        }
      });
    }
    setIsUpdateAvailable(false);
  };

  // ì´ˆê¸° ë©”ì‹œì§€ ì„¤ì •
  useEffect(() => {
    if (messages.length === 0) {
      setMessages([WELCOME_MESSAGE]);
      // ì›°ì»´ ë©”ì‹œì§€ ìŒì„± ì¶œë ¥
      setTimeout(() => {
        speakResponse(WELCOME_MESSAGE.text);
      }, 1000);
    }
  }, []);

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  // ì„¤ì¹˜ í”„ë¡¬í”„íŠ¸ í‘œì‹œ í•¨ìˆ˜
  const handleInstallClick = () => {
    if (deferredPrompt) {
      deferredPrompt.prompt();
      deferredPrompt.userChoice.then((choiceResult: { outcome: string }) => {
        if (choiceResult.outcome === 'accepted') {
          console.log('User accepted the install prompt');
        }
        setDeferredPrompt(null);
        setShowInstallPrompt(false);
      });
    }
  };

  // handleSendMessage í•¨ìˆ˜ ìˆ˜ì • - ê°„ë‹¨í•œ ì‘ë‹µê³¼ íƒ€ì´ë¨¸ ë¡œì§
  const handleSendMessage = async (messageText: string, currentMessages: Message[]) => {
    if (loading) {
      console.log('Already processing a message, ignoring:', messageText);
      return;
    }

    setLoading(true);

    try {
      const response = await openai.chat.completions.create({
        model: "gpt-4-turbo-preview",
        messages: [
          { 
            role: "system", 
            content: `You are helping a complete beginner learn English. Follow these rules strictly:
                     1. Keep responses very short and simple (max 2 sentences)
                     2. If there's a grammar mistake:
                        - First give a brief, natural response
                        - Then say "Correction:" and show the right way
                        - Give a quick example
                     3. If no mistakes:
                        - Just give a friendly, natural response
                        - Ask a simple follow-up question
                     4. Use only basic vocabulary
                     5. Total response must be under 30 words
                     6. Never use emojis or special characters
                     7. Be encouraging but brief`
          },
          ...currentMessages.map(msg => ({
            role: msg.sender === 'user' ? 'user' as const : 'assistant' as const,
            content: msg.text
          }))
        ],
        temperature: 0.7,
        max_tokens: 50
      });

      const aiResponse = response.choices[0].message.content;
      
      if (!aiResponse) {
        throw new Error('No response from AI');
      }

      const assistantMessage: Message = {
        text: aiResponse,
        sender: 'assistant'
      };

      setMessages(prev => [...prev, assistantMessage]);
      
      // AI ì‘ë‹µ í›„ ìŒì„± ì¶œë ¥
      setTimeout(() => {
        speakResponse(aiResponse);
        // ìŒì„± ì¶œë ¥ ì™„ë£Œ í›„ íƒ€ì´ë¨¸ ì‹œì‘
        startInactivityTimer();
      }, 500);

    } catch (error) {
      console.error('Error:', error);
      setMessages(prev => [...prev, {
        text: "I'm sorry, I couldn't understand. Can you say that again?",
        sender: 'assistant'
      }]);
    } finally {
      setLoading(false);
    }
  };

  // Cancel ë²„íŠ¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
  const handleMicCancel = () => {
    if (currentUtterance.current) {
      stopAIVoice();
    }
    
    // ìŒì„± ì¸ì‹ ì¢…ë£Œ
    SpeechRecognition.stopListening();
    setIsListening(false);
    resetTranscript();
    setInputText('');
  };

  if (!browserSupportsSpeechRecognition) {
    return <div>Browser doesn't support speech recognition.</div>;
  }

  if (!isMicrophoneAvailable) {
    return <div>Please allow microphone access to use voice input.</div>;
  }

  return (
    <div className="chat-interface">
      {showInstallPrompt && (
        <div className="install-prompt">
          <div className="install-prompt-content">
            <p>ğŸ“± ì•±ì„ ì„¤ì¹˜í•˜ë©´ ë” í¸ë¦¬í•˜ê²Œ ì´ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!</p>
            <button onClick={handleInstallClick}>ì„¤ì¹˜í•˜ê¸°</button>
            <button onClick={() => setShowInstallPrompt(false)}>ë‚˜ì¤‘ì—</button>
          </div>
        </div>
      )}
      {isUpdateAvailable && (
        <div className="install-prompt">
          <div className="install-prompt-content">
            <p>ğŸ”„ ìƒˆë¡œìš´ ë²„ì „ì´ ìˆìŠµë‹ˆë‹¤. ì—…ë°ì´íŠ¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ?</p>
            <button onClick={handleUpdate}>ì—…ë°ì´íŠ¸</button>
            <button onClick={() => setIsUpdateAvailable(false)}>ë‚˜ì¤‘ì—</button>
          </div>
        </div>
      )}
      <div className="title-container">
        <h1 className="chat-title">
          <div className="title-main">
            <span>ğŸ’¬</span>
            <span>NoPlan, JustTalk</span>
          </div>
        </h1>
        <div style={{ fontSize: '12px', color: '#888', marginTop: '-8px', marginBottom: '4px', textAlign: 'center' }}>Ver 1.0.20</div>
      </div>
      
      <div className="chat-messages">
        {messages
          .filter((message) => message.text !== 'Ver 1.0.12')
          .map((message, index) => (
            <div key={index} className={`message-container ${message.sender}-container`}>
              <div className={`message ${message.sender}-message`}>
                {message.text}
                {message.sender === 'assistant' && !isListening && (
                  <button 
                    className="replay-button"
                    onClick={() => speakResponse(message.text)}
                    aria-label="Replay message"
                    disabled={isListening}
                  >
                    ğŸ”Š
                  </button>
                )}
              </div>
            </div>
        ))}
        {loading && !isListening && (
          <div className="message-container assistant-container">
            <div className="message assistant-message">
              <div className="typing-indicator">
                <span></span>
                <span></span>
                <span></span>
              </div>
            </div>
          </div>
        )}
        <div ref={messagesEndRef} />
      </div>

      <div className="chat-controls">
        <div className="chat-input-container">
          <input
            type="text"
            value={inputText}
            onChange={(e) => setInputText(e.target.value)}
            onKeyPress={handleKeyPress}
            placeholder={isListening ? 'Listening...' : 'Type your message...'}
            className="chat-input"
            disabled={loading || isListening}
          />
          <div className="button-container">
            <button
              onClick={handleMicClick}
              className={`mic-button ${isListening ? 'stop' : 'start'}`}
              disabled={loading && !isListening}
            >
              {isListening ? 'ğŸ”´ Stop' : 'ğŸ¤ Start'}
            </button>
            <button
              onClick={handleMicCancel}
              className="cancel-button"
              disabled={!isListening}
            >
              Cancel
            </button>
            <button
              onClick={handleSend}
              disabled={loading || !inputText.trim() || isListening}
              className="send-button"
            >
              {loading ? 'Sending...' : 'Send'}
            </button>
          </div>
        </div>
        {isListening && (
          <div className="listening-indicator">
            Listening... Speak in English
          </div>
        )}
      </div>
    </div>
  );
}

export default App;
